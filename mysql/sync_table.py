#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MySQLåˆ°TiDBé«˜é€ŸåŒæ­¥å·¥å…· - å®Œç¾ä¿®å¤ç‰ˆ

åŠŸèƒ½ç‰¹æ€§ï¼š
    âš¡ æé€Ÿå¢é‡åŒæ­¥ï¼ˆæ™ºèƒ½æ£€æµ‹æœ‰æ— æ–°æ•°æ®ï¼‰
    ğŸ”„ é˜²å¹¶å‘é—æ¼ï¼ˆæ¯5åˆ†é’Ÿå›é€€æ£€æŸ¥ï¼‰
    ğŸš€ é›¶å¼€é”€æ£€æµ‹ï¼Œåªåœ¨æœ‰æ•°æ®æ—¶åŒæ­¥
    ğŸ—ï¸ è‡ªåŠ¨å»ºåº“å»ºè¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    âš¡ å¯é€‰TiFlashå‰¯æœ¬è‡ªåŠ¨æ·»åŠ 
    ğŸ• å®Œç¾å…¼å®¹æ‰€æœ‰MySQLæ•°æ®ç±»å‹
    ğŸ§  è‡ªåŠ¨å¤„ç†æ—¶åŒºå’Œç¼–ç é—®é¢˜
    ğŸ“Š æ‰¹é‡å¤„ç†æ§åˆ¶
"""

import pymysql
import time
import threading
import logging
import signal
import sys
import argparse
import json
import os
from datetime import datetime

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')

def load_config(config_path):
    if not os.path.exists(config_path):
        example_config = {
            "source_mysql": {
                "host": "source.mysql.com",
                "port": 3306,
                "database": "source_database",
                "username": "source_user",
                "password": "source_password"
            },
            "target_tidb": {
                "host": "target.tidb.com",
                "port": 4000,
                "database": "target_database",
                "username": "target_user",
                "password": "target_password"
            },
            "sync_settings": {
                "batch_size": 1000,
                "tiflash_enabled": True
            },
            "tables": {
                "crm_item_main": {
                    "id_field": "id",
                    "time_field": "update_time"
                }
            }
        }
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(example_config, f, indent=4, ensure_ascii=False)
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå·²åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶: {config_path}")
        sys.exit(1)

    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        for key in ['source_mysql', 'target_tidb', 'tables']:
            if key not in config:
                raise KeyError(f"é…ç½®æ–‡ä»¶ç¼ºå°‘å¿…è¦é¡¹: {key}")
        logging.info(f"âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ: {config_path}")
        return config
    except Exception as e:
        print(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        sys.exit(1)

def smart_mysql_to_tidb_sync():
    parser = argparse.ArgumentParser(description='MySQLåˆ°TiDBé«˜é€ŸåŒæ­¥å·¥å…·')
    parser.add_argument('--config', default='config.json', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--reset', action='store_true', help='é‡ç½®è¡¨')
    parser.add_argument('--force', action='store_true', help='å¼ºåˆ¶æ‰§è¡Œ')
    args = parser.parse_args()

    config = load_config(args.config)
    SOURCE_MYSQL_CONFIG = config['source_mysql']
    target_tidb_CONFIG = config['target_tidb']
    TABLES = config['tables']

    # ğŸš€ è·å–åŒæ­¥è®¾ç½®
    SYNC_SETTINGS = config.get('sync_settings', {'batch_size': 1000, 'tiflash_enabled': True})
    BATCH_SIZE = SYNC_SETTINGS.get('batch_size', 1000)
    TIFLASH_ENABLED = SYNC_SETTINGS.get('tiflash_enabled', True)

    stop_event = threading.Event()
    last_backtrack_time = {}

    def create_source_connection():
        try:
            logging.info(f"ğŸ”— æ­£åœ¨è¿æ¥æºæ•°æ®åº“: {SOURCE_MYSQL_CONFIG['host']}:{SOURCE_MYSQL_CONFIG['port']}/{SOURCE_MYSQL_CONFIG['database']}")
            conn = pymysql.connect(
                host=SOURCE_MYSQL_CONFIG['host'],
                port=SOURCE_MYSQL_CONFIG['port'],
                user=SOURCE_MYSQL_CONFIG['username'],
                password=SOURCE_MYSQL_CONFIG['password'],
                database=SOURCE_MYSQL_CONFIG['database'],
                charset='utf8mb4',
                cursorclass=pymysql.cursors.DictCursor
            )
            logging.info(f"âœ… æºæ•°æ®åº“è¿æ¥æˆåŠŸ: {SOURCE_MYSQL_CONFIG['host']}:{SOURCE_MYSQL_CONFIG['port']}")
            return conn
        except Exception as e:
            logging.error(f"âŒ æºæ•°æ®åº“è¿æ¥å¤±è´¥ {SOURCE_MYSQL_CONFIG['host']}:{SOURCE_MYSQL_CONFIG['port']}: {e}")
            raise

    def create_target_connection():
        try:
            logging.info(f"ğŸ”— æ­£åœ¨è¿æ¥ç›®æ ‡æ•°æ®åº“: {target_tidb_CONFIG['host']}:{target_tidb_CONFIG['port']}/{target_tidb_CONFIG['database']}")
            conn = pymysql.connect(
                host=target_tidb_CONFIG['host'],
                port=target_tidb_CONFIG['port'],
                user=target_tidb_CONFIG['username'],
                password=target_tidb_CONFIG['password'],
                database=target_tidb_CONFIG['database'],
                charset='utf8mb4',
                cursorclass=pymysql.cursors.DictCursor
            )
            logging.info(f"âœ… ç›®æ ‡æ•°æ®åº“è¿æ¥æˆåŠŸ: {target_tidb_CONFIG['host']}:{target_tidb_CONFIG['port']}")
            return conn
        except Exception as e:
            logging.error(f"âŒ ç›®æ ‡æ•°æ®åº“è¿æ¥å¤±è´¥ {target_tidb_CONFIG['host']}:{target_tidb_CONFIG['port']}: {e}")
            raise

    def create_database_if_not_exists():
        """ğŸ—ï¸ è‡ªåŠ¨åˆ›å»ºç›®æ ‡æ•°æ®åº“"""
        try:
            logging.info(f"ğŸ”— æ­£åœ¨è¿æ¥ç›®æ ‡æœåŠ¡å™¨åˆ›å»ºæ•°æ®åº“: {target_tidb_CONFIG['host']}:{target_tidb_CONFIG['port']}")
            # è¿æ¥åˆ°æœåŠ¡å™¨ä½†ä¸æŒ‡å®šæ•°æ®åº“
            conn = pymysql.connect(
                host=target_tidb_CONFIG['host'],
                port=target_tidb_CONFIG['port'],
                user=target_tidb_CONFIG['username'],
                password=target_tidb_CONFIG['password'],
                charset='utf8mb4'
            )
            with conn.cursor() as cursor:
                cursor.execute(f"CREATE DATABASE IF NOT EXISTS `{target_tidb_CONFIG['database']}` CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci")
                conn.commit()
            conn.close()
            logging.info(f"âœ… ç›®æ ‡æ•°æ®åº“ç¡®ä¿å­˜åœ¨: {target_tidb_CONFIG['database']}")
            return True
        except Exception as e:
            logging.error(f"âŒ åˆ›å»ºç›®æ ‡æ•°æ®åº“å¤±è´¥: {e}")
            return False

    def get_table_structure(source_conn, table_name):
        """è·å–æºè¡¨ç»“æ„"""
        try:
            logging.info(f"ğŸ“‹ æ­£åœ¨è·å–æºè¡¨ç»“æ„: {table_name}")
            with source_conn.cursor() as cursor:
                cursor.execute(f"SHOW CREATE TABLE {table_name}")
                result = cursor.fetchone()
                logging.info(f"âœ… æºè¡¨ç»“æ„è·å–æˆåŠŸ: {table_name}")
                return result['Create Table']
        except Exception as e:
            logging.error(f"âŒ è·å–æºè¡¨ç»“æ„å¤±è´¥ {table_name}: {e}")
            return None

    def create_target_table(target_conn, table_name, create_sql):
        """åœ¨ç›®æ ‡æ•°æ®åº“åˆ›å»ºè¡¨"""
        try:
            logging.info(f"ğŸ—ï¸ æ­£åœ¨åˆ›å»ºç›®æ ‡è¡¨: {table_name}")
            with target_conn.cursor() as cursor:
                # æ›¿æ¢è¡¨åï¼Œé˜²æ­¢æ•°æ®åº“åå†²çª
                create_sql = create_sql.replace(f'`{SOURCE_MYSQL_CONFIG["database"]}`.', '')
                cursor.execute(create_sql)
                target_conn.commit()
                logging.info(f"âœ… ç›®æ ‡è¡¨åˆ›å»ºæˆåŠŸ: {table_name}")
                return True
        except Exception as e:
            logging.error(f"âŒ åˆ›å»ºç›®æ ‡è¡¨å¤±è´¥ {table_name}: {e}")
            return False

    def table_exists(conn, table_name, db_type=""):
        """æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨"""
        try:
            with conn.cursor() as cursor:
                cursor.execute(f"SHOW TABLES LIKE '{table_name}'")
                exists = cursor.fetchone() is not None
                if exists:
                    logging.info(f"â„¹ï¸  {db_type}è¡¨å·²å­˜åœ¨: {table_name}")
                else:
                    logging.info(f"âš ï¸  {db_type}è¡¨ä¸å­˜åœ¨: {table_name}")
                return exists
        except Exception as e:
            logging.error(f"âŒ æ£€æŸ¥{db_type}è¡¨å­˜åœ¨æ€§å¤±è´¥ {table_name}: {e}")
            return False

    def get_table_columns(conn, table_name):
        """è·å–è¡¨çš„åˆ—ä¿¡æ¯"""
        try:
            with conn.cursor() as cursor:
                cursor.execute(f"DESCRIBE {table_name}")
                columns = cursor.fetchall()
                return [col['Field'] for col in columns]
        except Exception as e:
            logging.error(f"âŒ è·å–è¡¨åˆ—ä¿¡æ¯å¤±è´¥ {table_name}: {e}")
            return []

    def add_tiflash_replica(target_conn, table_name):
        """æ·»åŠ TiFlashå‰¯æœ¬"""
        if not TIFLASH_ENABLED:
            logging.info(f"âš ï¸  TiFlashåŠŸèƒ½å·²ç¦ç”¨ï¼Œè·³è¿‡ {table_name}")
            return False

        try:
            logging.info(f"âš¡ æ­£åœ¨ä¸ºç›®æ ‡è¡¨æ·»åŠ TiFlashå‰¯æœ¬: {table_name}")
            with target_conn.cursor() as cursor:
                cursor.execute(f"ALTER TABLE {table_name} SET TIFLASH REPLICA 1")
                target_conn.commit()
                logging.info(f"âš¡ ç›®æ ‡è¡¨TiFlashå‰¯æœ¬æ·»åŠ æˆåŠŸ: {table_name}")
                return True
        except Exception as e:
            logging.warning(f"âš ï¸  ç›®æ ‡è¡¨TiFlashå‰¯æœ¬æ·»åŠ å¤±è´¥ {table_name}: {e}")
            return False

    def reset_tables():
        if not args.force:
            print("âš ï¸  è­¦å‘Šï¼šè¿™å°†åˆ é™¤ç›®æ ‡æ•°æ®åº“ä¸­çš„æ‰€æœ‰ç°æœ‰è¡¨ï¼")
            if input("ç¡®è®¤é‡ç½®ï¼Ÿ(è¾“å…¥ 'yes' ç¡®è®¤): ").lower() != 'yes':
                return False

        # ğŸ—ï¸ ç¡®ä¿ç›®æ ‡æ•°æ®åº“å­˜åœ¨
        if not create_database_if_not_exists():
            return False

        target_conn = create_target_connection()
        try:
            with target_conn.cursor() as cursor:
                for table_name in TABLES.keys():
                    try:
                        cursor.execute(f"DROP TABLE IF EXISTS {table_name}")
                        target_conn.commit()
                        logging.info(f"ğŸ—‘ï¸  å·²åˆ é™¤ç›®æ ‡è¡¨: {table_name}")
                    except Exception as e:
                        logging.warning(f"âš ï¸  åˆ é™¤ç›®æ ‡è¡¨å¤±è´¥: {e}")
        finally:
            target_conn.close()
        return True

    def init_setup():
        if args.reset and not reset_tables():
            return False

        # ğŸ—ï¸ ç¡®ä¿ç›®æ ‡æ•°æ®åº“å­˜åœ¨
        if not create_database_if_not_exists():
            return False

        source_conn = create_source_connection()
        target_conn = create_target_connection()

        try:
            for table_name, table_config in TABLES.items():
                # æ£€æŸ¥æºè¡¨æ˜¯å¦å­˜åœ¨
                if not table_exists(source_conn, table_name, "æº"):
                    logging.error(f"âŒ æºè¡¨ä¸å­˜åœ¨: {table_name}")
                    continue

                # æ£€æŸ¥ç›®æ ‡è¡¨æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»º
                if not table_exists(target_conn, table_name, "ç›®æ ‡"):
                    logging.info(f"ğŸ—ï¸  ç›®æ ‡è¡¨ä¸å­˜åœ¨ï¼Œæ­£åœ¨ä»æºè¡¨åˆ›å»º: {table_name}")
                    create_sql = get_table_structure(source_conn, table_name)
                    if create_sql and create_target_table(target_conn, table_name, create_sql):
                        logging.info(f"âœ… ç›®æ ‡è¡¨åˆ›å»ºæˆåŠŸ: {table_name}")

                        # ğŸš€ æ ¹æ®é…ç½®å†³å®šæ˜¯å¦æ·»åŠ TiFlashå‰¯æœ¬
                        add_tiflash_replica(target_conn, table_name)

                    else:
                        logging.error(f"âŒ ç›®æ ‡è¡¨åˆ›å»ºå¤±è´¥: {table_name}")
                        continue
                else:
                    logging.info(f"â„¹ï¸  ç›®æ ‡è¡¨å·²å­˜åœ¨: {table_name}")

                    # ğŸš€ ä¸ºå·²å­˜åœ¨çš„ç›®æ ‡è¡¨æ·»åŠ TiFlashå‰¯æœ¬ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                    add_tiflash_replica(target_conn, table_name)

                # åˆå§‹åŒ–å›é€€æ—¶é—´
                last_backtrack_time[table_name] = time.time()

        finally:
            source_conn.close()
            target_conn.close()

        logging.info("âœ… åˆå§‹åŒ–å®Œæˆ")
        return True

    def get_max_timestamp_with_backtrack(target_conn, table_name, time_field):
        """ğŸ§  æ™ºèƒ½è·å–ç›®æ ‡è¡¨æœ€å¤§æ—¶é—´æˆ³ - ä¿®å¤ç²¾åº¦é—®é¢˜"""
        try:
            with target_conn.cursor() as cursor:
                # ğŸ”¥ å…³é”®ä¿®å¤ï¼šä½¿ç”¨å¾®ç§’ç²¾åº¦æ¯”è¾ƒï¼Œé¿å…åŒä¸€ç§’å†…æ•°æ®é—æ¼
                cursor.execute(f"SELECT MAX({time_field}) as max_time FROM {table_name}")
                result = cursor.fetchone()
                max_time = result['max_time'] if result and result['max_time'] else None

                if not max_time:
                    return "1970-01-01 00:00:00.000000", False

                current_time = time.time()
                # ğŸ”„ æ¯5åˆ†é’Ÿå›é€€ä¸€æ¬¡
                should_backtrack = current_time - last_backtrack_time.get(table_name, 0) >= 300

                if should_backtrack:
                    # ğŸ”§ ä¿®å¤ï¼šå›é€€åˆ°ç›®æ ‡è¡¨æœ€å¤§æ—¶é—´å¾€å‰5åˆ†é’Ÿ
                    cursor.execute(f"SELECT DATE_SUB(MAX({time_field}), INTERVAL 5 MINUTE) as backtrack_time FROM {table_name}")
                    backtrack_result = cursor.fetchone()
                    backtrack_time = backtrack_result['backtrack_time'] if backtrack_result else max_time
                    last_backtrack_time[table_name] = current_time
                    return backtrack_time, True
                else:
                    return max_time, False

        except Exception as e:
            logging.warning(f"âš ï¸  è·å–ç›®æ ‡è¡¨æ—¶é—´æˆ³å¤±è´¥ {table_name}: {e}")
            return "1970-01-01 00:00:00.000000", False

    def sync_data_ultra_fast(table_name, table_config):
        """âš¡ è¶…é«˜é€ŸåŒæ­¥ï¼Œä½¿ç”¨INSERT ON DUPLICATE KEY UPDATEä¼˜åŒ–"""
        if stop_event.is_set():
            return False

        time_field = table_config['time_field']
        id_field = table_config['id_field']

        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šåœ¨å‡½æ•°å¼€å§‹æ—¶åˆå§‹åŒ–æ‰€æœ‰å˜é‡ï¼Œé¿å…UnboundLocalError
        source_conn = None
        target_conn = None

        try:
            # ğŸ”¥ ä¿®å¤ï¼šç¡®ä¿target_connåœ¨ä½¿ç”¨å‰å·²æ­£ç¡®åˆå§‹åŒ–
            target_conn = pymysql.connect(
                host=target_tidb_CONFIG['host'],
                port=target_tidb_CONFIG['port'],
                user=target_tidb_CONFIG['username'],
                password=target_tidb_CONFIG['password'],
                database=target_tidb_CONFIG['database'],
                charset='utf8mb4',
                cursorclass=pymysql.cursors.DictCursor
            )

            max_time, is_backtrack = get_max_timestamp_with_backtrack(target_conn, table_name, time_field)

            source_conn = pymysql.connect(
                host=SOURCE_MYSQL_CONFIG['host'],
                port=SOURCE_MYSQL_CONFIG['port'],
                user=SOURCE_MYSQL_CONFIG['username'],
                password=SOURCE_MYSQL_CONFIG['password'],
                database=SOURCE_MYSQL_CONFIG['database'],
                charset='utf8mb4',
                cursorclass=pymysql.cursors.DictCursor
            )

            # ğŸ” ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨æ—¶é—´å­—æ®µæ¯”è¾ƒï¼Œä¿æŒå®Œæ•´ç²¾åº¦
            with source_conn.cursor() as cursor:
                # ğŸ”¥ å…³é”®ä¿®å¤ï¼šä½¿ç”¨ > è€Œä¸æ˜¯ UNIX_TIMESTAMP æ¯”è¾ƒ
                check_sql = f"SELECT COUNT(*) as count FROM {table_name} WHERE {time_field} > %s"
                cursor.execute(check_sql, (max_time,))
                result = cursor.fetchone()
                new_count = result['count']

                # ğŸš€ åªæœ‰ç¡®å®æœ‰æ–°æ•°æ®æ—¶æ‰æ‰§è¡ŒåŒæ­¥
                if new_count > 0:
                    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šè·å–æ•°æ®æ—¶ä¹Ÿä½¿ç”¨ç›´æ¥æ—¶é—´æ¯”è¾ƒ
                    sync_sql = f"SELECT * FROM {table_name} WHERE {time_field} > %s ORDER BY {time_field}, {id_field} LIMIT %s"
                    cursor.execute(sync_sql, (max_time, BATCH_SIZE))
                    new_data = cursor.fetchall()

                    if new_data:
                        # è·å–ç›®æ ‡è¡¨åˆ—ä¿¡æ¯
                        columns = get_table_columns(target_conn, table_name)
                        if not columns:
                            return False

                        # ğŸš€ ä½¿ç”¨ INSERT ON DUPLICATE KEY UPDATE è¯­å¥ï¼Œæ€§èƒ½æ›´ä¼˜
                        placeholders = ', '.join(['%s'] * len(columns))
                        columns_str = ', '.join([f'`{col}`' for col in columns])

                        # æ„å»ºUPDATEå­å¥ï¼Œæ’é™¤ä¸»é”®å­—æ®µ
                        update_assignments = []
                        for col in columns:
                            if col != id_field:  # å‡è®¾id_fieldæ˜¯ä¸»é”®ï¼Œä¸éœ€è¦æ›´æ–°
                                update_assignments.append(f"`{col}` = VALUES(`{col}`)")

                        update_clause = ', '.join(update_assignments)

                        # ğŸ”¥ å…³é”®ä¼˜åŒ–ï¼šä½¿ç”¨INSERT ON DUPLICATE KEY UPDATE
                        upsert_sql = f"""
                        INSERT INTO {table_name} ({columns_str}) 
                        VALUES ({placeholders})
                        ON DUPLICATE KEY UPDATE {update_clause}
                        """

                        # æ‰¹é‡æ’å…¥æ•°æ®åˆ°ç›®æ ‡è¡¨
                        with target_conn.cursor() as target_cursor:
                            data_to_insert = []
                            for row in new_data:
                                row_data = [row.get(col) for col in columns]
                                data_to_insert.append(row_data)

                            target_cursor.executemany(upsert_sql, data_to_insert)
                            target_conn.commit()

                        # ğŸ”¢ æ˜¾ç¤ºæ‰¹é‡ä¿¡æ¯
                        if new_count > BATCH_SIZE:
                            remaining = new_count - len(new_data)
                            if is_backtrack:
                                logging.info(f"ğŸ”„ {table_name}: 5åˆ†é’Ÿå›é€€æ£€æŸ¥ï¼Œä½¿ç”¨UPSERTåŒæ­¥ {len(new_data)} æ¡ï¼Œè¿˜æœ‰ {remaining} æ¡å¾…å¤„ç†")
                            else:
                                logging.info(f"âš¡ {table_name}: ä½¿ç”¨UPSERTåŒæ­¥ {len(new_data)} æ¡ï¼Œè¿˜æœ‰ {remaining} æ¡å¾…å¤„ç†")
                        else:
                            if is_backtrack:
                                logging.info(f"ğŸ”„ {table_name}: 5åˆ†é’Ÿå›é€€æ£€æŸ¥å®Œæˆï¼Œä½¿ç”¨UPSERTåŒæ­¥ {len(new_data)} æ¡æ•°æ®")
                            else:
                                logging.info(f"âš¡ {table_name}: ä½¿ç”¨UPSERTåŒæ­¥ {len(new_data)} æ¡æ–°æ•°æ®")
                        return True
                    else:
                        return False
                else:
                    return False

        except Exception as e:
            if not stop_event.is_set():
                # ğŸ”¥ ä¿®å¤ï¼šç¡®ä¿table_nameå˜é‡åœ¨å¼‚å¸¸å¤„ç†æ—¶å¯ç”¨
                logging.error(f"âŒ {table_name} UPSERTåŒæ­¥å¤±è´¥: {e}")
            return False
        finally:
            # ğŸ”¥ ä¿®å¤ï¼šç¡®ä¿è¿æ¥å¯¹è±¡å­˜åœ¨æ—¶æ‰å…³é—­
            if source_conn:
                source_conn.close()
            if target_conn:
                target_conn.close()

    def incremental_sync():
        logging.info("ğŸš€ è¶…é«˜é€ŸåŒæ­¥å¯åŠ¨ï¼ˆæ™ºèƒ½æ£€æµ‹æ¨¡å¼ï¼‰")
        logging.info(f"ğŸ“¡ æºæ•°æ®åº“: {SOURCE_MYSQL_CONFIG['host']}:{SOURCE_MYSQL_CONFIG['port']}/{SOURCE_MYSQL_CONFIG['database']}")
        logging.info(f"ğŸ¯ ç›®æ ‡æ•°æ®åº“: {target_tidb_CONFIG['host']}:{target_tidb_CONFIG['port']}/{target_tidb_CONFIG['database']}")

        try:
            while not stop_event.is_set():
                for table_name, table_config in TABLES.items():
                    if stop_event.is_set():
                        break
                    sync_data_ultra_fast(table_name, table_config)

                if stop_event.is_set():
                    break

                # â±ï¸ å›ºå®š0.5ç§’è½®è¯¢é—´éš”
                stop_event.wait(0.5)

        except Exception as e:
            if not stop_event.is_set():
                logging.error(f"âŒ åŒæ­¥å¼‚å¸¸: {e}")
        finally:
            logging.info("ğŸ›‘ åŒæ­¥å·²åœæ­¢")

    def signal_handler(signum, frame):
        logging.info("ğŸ›‘ æ­£åœ¨é€€å‡º...")
        stop_event.set()

    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    try:
        if not init_setup():
            return

        if args.reset:
            logging.info("ğŸ”„ é‡ç½®å®Œæˆ")
            return

        inc_thread = threading.Thread(target=incremental_sync)
        inc_thread.start()

        logging.info("ğŸš€ MySQLåˆ°TiDBè¶…é«˜é€ŸåŒæ­¥å·²å¯åŠ¨")
        logging.info(f"ğŸ“‹ ç›‘æ§è¡¨: {', '.join(TABLES.keys())}")
        logging.info(f"ğŸ“Š æ‰¹é‡å¤„ç†å¤§å°: {BATCH_SIZE}")
        logging.info(f"âš¡ TiFlashåŠŸèƒ½: {'å¯ç”¨' if TIFLASH_ENABLED else 'ç¦ç”¨'}")
        logging.info("ğŸ—ï¸ è‡ªåŠ¨å»ºåº“å»ºè¡¨ï¼šç›®æ ‡ä¸å­˜åœ¨æ—¶è‡ªåŠ¨åˆ›å»º")
        logging.info("ğŸ”„ æ¯5åˆ†é’Ÿè‡ªåŠ¨å›é€€æ£€æŸ¥")
        logging.info("ğŸ§  æ™ºèƒ½å…¼å®¹æ‰€æœ‰MySQLæ•°æ®ç±»å‹")
        logging.info("ğŸš€ ä½¿ç”¨INSERT ON DUPLICATE KEY UPDATEè‡ªåŠ¨å¤„ç†ä¸»é”®å†²çª")
        logging.info("âš¡ å…ˆæ£€æµ‹ååŒæ­¥ï¼Œé›¶æ— æ•ˆå¼€é”€")
        logging.info("ğŸ“Š é™é»˜æ¨¡å¼ï¼šæ— æ–°æ•°æ®æ—¶ä¸è¾“å‡ºæ—¥å¿—")
        logging.info("â±ï¸ å›ºå®š0.5ç§’è½®è¯¢é—´éš”")
        logging.info("ğŸ’¡ æŒ‰ Ctrl+C é€€å‡º")

        while not stop_event.is_set():
            stop_event.wait(1)

        inc_thread.join(timeout=5)
        logging.info("ğŸ›‘ å·²åœæ­¢")

    except Exception as e:
        logging.error(f"âŒ å¼‚å¸¸: {e}")
        stop_event.set()
    finally:
        sys.exit(0)

if __name__ == "__main__":
    smart_mysql_to_tidb_sync()
